{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small learning rate(1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "1 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "2 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "3 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "4 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "5 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "6 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "7 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "8 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "9 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "10 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "11 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "12 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "13 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "14 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "15 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "16 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "17 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "18 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "19 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "20 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "21 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "22 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "23 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "24 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "25 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "26 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "27 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "28 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "29 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "30 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "31 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "32 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "33 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "34 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "35 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "36 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "37 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "38 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "39 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "40 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "41 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "42 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "43 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "44 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "45 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "46 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "47 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "48 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "49 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "50 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "51 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "52 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "53 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "54 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "55 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "56 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "57 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "58 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "59 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "60 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "61 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "62 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "63 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "64 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "65 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "66 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "67 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "68 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "69 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "70 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "71 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "72 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "73 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "74 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "75 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "76 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "77 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "78 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "79 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "80 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "81 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "82 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "83 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "84 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "85 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "86 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "87 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "88 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "89 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "90 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "91 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "92 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "93 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "94 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "95 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "96 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "97 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "98 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "99 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "100 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "101 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "102 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "103 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "104 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "105 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "106 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "107 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "108 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "109 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "110 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "111 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "112 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "113 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "114 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "115 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "116 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "117 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "118 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "119 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "120 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "122 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "123 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "124 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "125 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "126 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "127 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "128 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "129 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "130 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "131 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "132 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "133 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "134 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "135 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "136 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "137 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "138 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "139 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "140 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "141 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "142 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "143 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "144 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "145 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "146 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "147 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "148 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "149 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "150 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "151 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "152 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "153 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "154 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "155 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "156 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "157 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "158 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "159 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "160 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "161 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "162 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "163 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "164 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "165 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "166 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "167 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "168 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "169 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "170 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "171 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "172 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "173 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "174 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "175 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "176 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "177 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "178 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "179 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "180 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "181 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "182 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "183 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "184 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "185 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "186 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "187 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "188 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "189 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "190 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "191 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "192 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "193 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "195 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "196 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "197 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "198 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "199 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "200 6.20213 [[-0.82212889 -0.2921983   0.9995392 ]\n",
      " [ 1.22073805 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "Prediction: [0 2 0]\n",
      "Accuracy:  0.333333\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big learning rate (1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.10744 [[-1.30222011  1.34119952  0.0091089 ]\n",
      " [-2.26837182  2.60242152  1.24224782]\n",
      " [-1.71102452  2.79830837  0.74882114]]\n",
      "1 19.6157 [[-0.92722011  0.40457785  0.57073057]\n",
      " [ 0.16912818 -1.3332932   2.7404623 ]\n",
      " [ 0.72647548 -0.95078254  2.06041241]]\n",
      "2 20.9345 [[-0.5522275   0.96707761 -0.36676174]\n",
      " [ 2.60661316  1.29170609 -2.32202244]\n",
      " [ 3.16396785  1.86171699 -3.18957996]]\n",
      "3 14.2091 [[-1.65749359  1.50984383  0.1957382 ]\n",
      " [-1.477355    3.87567449 -0.82202256]\n",
      " [-0.93907952  4.6522646  -1.87707996]]\n",
      "4 29.6629 [[-1.28249359  0.57234383  0.7582382 ]\n",
      " [ 0.960145   -0.06182551  0.67797744]\n",
      " [ 1.49842048  0.9022646  -0.56457996]]\n",
      "5 2.70875 [[-2.1213994   1.08563483  1.08385301]\n",
      " [-2.48576164  2.43954015  1.62251794]\n",
      " [-2.16142678  3.57455683  0.42297524]]\n",
      "6 21.4102 [[-1.7463994   0.1596539   1.63483393]\n",
      " [-0.04826164 -1.47469449  3.0992527 ]\n",
      " [ 0.27607322 -0.16369581  1.72372794]]\n",
      "7 22.7472 [[-1.3713994   0.7221539   0.69733405]\n",
      " [ 2.38923812  1.15030551 -1.9632473 ]\n",
      " [ 2.71357298  2.64880419 -3.52627206]]\n",
      "8 9.49767 [[-2.1904912   0.97874892  1.25983071]\n",
      " [-1.00528169  3.04483199 -0.46325374]\n",
      " [-0.5071156   4.55699635 -2.21377516]]\n",
      "9 24.5151 [[-1.8154912   0.04125154  1.82232809]\n",
      " [ 1.43221831 -0.892663    1.03674102]\n",
      " [ 1.9303844   0.80699873 -0.90127778]]\n",
      "10 5.89277 [[-2.61158514  0.60353321  2.05614042]\n",
      " [-1.89120817  1.73183107  1.73567402]\n",
      " [-1.71694136  3.61889148 -0.06584394]]\n",
      "11 17.3951 [[-2.23658514 -0.17213708  2.45681071]\n",
      " [ 0.54629183 -1.86655998  2.8965652 ]\n",
      " [ 0.72055864  0.04619265  1.06935465]]\n",
      "12 19.8981 [[-1.86158514  0.39036292  1.51931083]\n",
      " [ 2.98379159  0.75844002 -2.1659348 ]\n",
      " [ 3.15805864  2.85869265 -4.18064547]]\n",
      "13 12.0791 [[-2.93929601  0.90557969  2.08180499]\n",
      " [-1.04190612  3.28414893 -0.6659466 ]\n",
      " [-0.86812401  5.57238102 -2.86815143]]\n",
      "14 28.7696 [[-2.56429601 -0.03191906  2.6443038 ]\n",
      " [ 1.39559388 -0.65334868  0.83405101]\n",
      " [ 1.56937599  1.82238245 -1.55565262]]\n",
      "15 2.29306 [[-3.14567327  0.36015829  2.83360362]\n",
      " [-1.41568494  1.59062123  1.4013598 ]\n",
      " [-1.16873646  3.82184291 -0.81700027]]\n",
      "16 16.3088 [[-2.77067327 -0.40258059  3.22134256]\n",
      " [ 1.02181506 -1.98717022  2.54165125]\n",
      " [ 1.26876354  0.25679231  0.31055021]]\n",
      "17 15.5926 [[-2.39567709  0.15991941  2.28384638]\n",
      " [ 3.45930696  0.63782978 -2.52084017]\n",
      " [ 3.70624495  3.06929231 -4.93943119]]\n",
      "18 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "19 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "20 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "21 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "22 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "23 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "24 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "25 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "26 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "27 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "28 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "29 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "30 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "31 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "32 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "33 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "34 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "35 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "36 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "37 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "38 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "39 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "40 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "41 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "42 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "43 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "44 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "45 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "46 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "47 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "48 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "49 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "50 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "51 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "52 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "53 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "54 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "55 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "56 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "57 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "58 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "59 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "60 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "61 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "62 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "63 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "64 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "65 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "66 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "67 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "68 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "69 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "70 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "71 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "72 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "73 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "74 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "75 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "76 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "77 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "78 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "79 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "80 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "81 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "82 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "83 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "84 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "85 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "86 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "87 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "88 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "89 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "90 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "91 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "92 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "93 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "94 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "95 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "96 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "97 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "98 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "99 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "100 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "101 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "102 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "103 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "104 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "105 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "106 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "107 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "108 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "109 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "110 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "111 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "112 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "113 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "114 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "115 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "116 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "117 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "118 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "119 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "120 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "122 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "123 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "124 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "125 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "126 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "127 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "128 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "129 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "130 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "131 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "132 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "133 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "134 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "135 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "136 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "137 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "138 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "139 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "140 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "141 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "142 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "143 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "144 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "145 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "146 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "147 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "148 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "149 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "150 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "151 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "152 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "153 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "154 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "155 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "156 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "157 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "158 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "159 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "160 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "161 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "162 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "163 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "164 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "165 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "166 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "167 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "168 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "169 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "170 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "171 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "172 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "173 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "174 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "175 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "176 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "177 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "178 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "179 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "180 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "181 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "182 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "183 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "184 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "185 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "186 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "187 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "188 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "189 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "190 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "191 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "192 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "193 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "194 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "195 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "196 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "197 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "198 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "199 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "200 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=1.5).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## suitable learning rate (0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.35157 [[-0.1952599  -0.21526977 -1.37132132]\n",
      " [ 0.58103514 -0.71268034  1.03534222]\n",
      " [ 1.442307   -0.27379474  0.76180577]]\n",
      "1 5.92088 [[-0.26293892 -0.17831673 -1.34059536]\n",
      " [ 0.33468652 -0.53880268  1.10781324]\n",
      " [ 1.19022202 -0.08687477  0.8269707 ]]\n",
      "2 4.43107 [[-0.28509218 -0.14258973 -1.35416913]\n",
      " [ 0.33232632 -0.36754179  0.93891257]\n",
      " [ 1.16293693  0.09856234  0.66881877]]\n",
      "3 3.42136 [[-0.33150822 -0.1089743  -1.34136856]\n",
      " [ 0.19287613 -0.20108108  0.91190207]\n",
      " [ 1.00459945  0.28090659  0.64481205]]\n",
      "4 2.48839 [[-0.35020867 -0.08142696 -1.35021544]\n",
      " [ 0.19198261 -0.04991347  0.76162797]\n",
      " [ 0.9783833   0.44958621  0.50234854]]\n",
      "5 1.74744 [[-0.38227996 -0.06580876 -1.33376241]\n",
      " [ 0.09425901  0.06281688  0.74662125]\n",
      " [ 0.86484277  0.57797235  0.48750293]]\n",
      "6 1.48368 [[-0.38271582 -0.07724877 -1.32188654]\n",
      " [ 0.14463106  0.06038029  0.69868577]\n",
      " [ 0.90660936  0.58233917  0.44136956]]\n",
      "7 1.4471 [[-0.39531612 -0.08633231 -1.30020273]\n",
      " [ 0.1284782   0.06504714  0.71017176]\n",
      " [ 0.88298613  0.59710056  0.45023143]]\n",
      "8 1.43162 [[-0.40144679 -0.09889509 -1.28150928]\n",
      " [ 0.14614758  0.05376983  0.70377976]\n",
      " [ 0.89348406  0.59414864  0.44268546]]\n",
      "9 1.41853 [[-0.41155353 -0.1082145  -1.26208317]\n",
      " [ 0.14318201  0.05789002  0.70262516]\n",
      " [ 0.88331199  0.60694814  0.44005805]]\n",
      "10 1.40614 [[-0.41900361 -0.1197269  -1.24312067]\n",
      " [ 0.15339485  0.05141816  0.69888419]\n",
      " [ 0.88688225  0.60838175  0.43505418]]\n",
      "11 1.39409 [[-0.42818457 -0.12965804 -1.22400856]\n",
      " [ 0.15452172  0.05246408  0.69671142]\n",
      " [ 0.88147599  0.6172834   0.43155882]]\n",
      "12 1.38228 [[-0.43615189 -0.14057259 -1.20512664]\n",
      " [ 0.16151251  0.04866844  0.69351625]\n",
      " [ 0.88232791  0.62083977  0.42715049]]\n",
      "13 1.37065 [[-0.44488969 -0.15072975 -1.18623173]\n",
      " [ 0.16430335  0.04840499  0.69098884]\n",
      " [ 0.87916523  0.62774485  0.42340809]]\n",
      "14 1.35917 [[-0.4530572  -0.16130474 -1.16748917]\n",
      " [ 0.16971216  0.04599078  0.68799424]\n",
      " [ 0.87892312  0.63212085  0.41927421]]\n",
      "15 1.34784 [[-0.46156177 -0.17149819 -1.14879119]\n",
      " [ 0.1731317   0.04527225  0.68529326]\n",
      " [ 0.87689847  0.6379621   0.41545758]]\n",
      "16 1.33666 [[-0.46978834 -0.18184988 -1.1302129 ]\n",
      " [ 0.17769733  0.04362774  0.68237215]\n",
      " [ 0.87627161  0.64256507  0.41148147]]\n",
      "17 1.3256 [[-0.47815424 -0.19199045 -1.11170638]\n",
      " [ 0.18128851  0.04283199  0.67957675]\n",
      " [ 0.87487513  0.64777565  0.40766737]]\n",
      "18 1.31468 [[-0.48637572 -0.20216887 -1.09330654]\n",
      " [ 0.18535629  0.04166743  0.67667353]\n",
      " [ 0.87417454  0.65234411  0.40379953]]\n",
      "19 1.3039 [[-0.49464568 -0.2122131  -1.0749923 ]\n",
      " [ 0.18892072  0.04095675  0.67381978]\n",
      " [ 0.87316453  0.65712959  0.40002406]]\n",
      "20 1.29324 [[-0.50283247 -0.22223836 -1.05678022]\n",
      " [ 0.19265787  0.04012996  0.6709094 ]\n",
      " [ 0.87252283  0.66155183  0.39624348]]\n",
      "21 1.28272 [[-0.51102567 -0.23216374 -1.0386616 ]\n",
      " [ 0.19611363  0.03956962  0.66801399]\n",
      " [ 0.8717798   0.66601396  0.39252439]]\n",
      "22 1.27232 [[-0.51916373 -0.24204257 -1.02064466]\n",
      " [ 0.19960575  0.03900628  0.6650852 ]\n",
      " [ 0.87124974  0.67024571  0.38882273]]\n",
      "23 1.26206 [[-0.52728856 -0.2518363  -1.0027262 ]\n",
      " [ 0.20292324  0.0386181   0.66215587]\n",
      " [ 0.87071073  0.67443824  0.38516924]]\n",
      "24 1.25192 [[-0.53537107 -0.2615695  -0.98491049]\n",
      " [ 0.20621748  0.03827587  0.65920389]\n",
      " [ 0.87030876  0.67846555  0.38154393]]\n",
      "25 1.24191 [[-0.54343086 -0.27122346 -0.96719676]\n",
      " [ 0.20939073  0.0380622   0.65624428]\n",
      " [ 0.8699376   0.68241954  0.3779611 ]]\n",
      "26 1.23203 [[-0.55145419 -0.28080931 -0.94958758]\n",
      " [ 0.21251599  0.03791405  0.6532672 ]\n",
      " [ 0.86966431  0.68624192  0.37441197]]\n",
      "27 1.22227 [[-0.55945009 -0.29031771 -0.93208325]\n",
      " [ 0.21554877  0.03786898  0.65027952]\n",
      " [ 0.86943734  0.68997771  0.37090319]]\n",
      "28 1.21264 [[-0.56741196 -0.29975358 -0.91468555]\n",
      " [ 0.21852516  0.03789529  0.64727682]\n",
      " [ 0.86928695  0.6936003   0.36743101]]\n",
      "29 1.20314 [[-0.57534403 -0.30911198 -0.89739507]\n",
      " [ 0.22142525  0.03800957  0.64426243]\n",
      " [ 0.869187    0.69713265  0.36399865]]\n",
      "30 1.19377 [[-0.58324295 -0.31839496 -0.88021314]\n",
      " [ 0.22426784  0.03819492  0.64123452]\n",
      " [ 0.86915076  0.70056295  0.36060455]]\n",
      "31 1.18452 [[-0.59111071 -0.32759973 -0.86314058]\n",
      " [ 0.22704452  0.03845807  0.63819468]\n",
      " [ 0.86916435  0.70390362  0.35725033]]\n",
      "32 1.17539 [[-0.59894556 -0.33672702 -0.84617847]\n",
      " [ 0.22976562  0.03878937  0.63514227]\n",
      " [ 0.86923295  0.70714992  0.35393542]]\n",
      "33 1.16639 [[-0.60674834 -0.34577516 -0.82932752]\n",
      " [ 0.23242822  0.0391908   0.63207823]\n",
      " [ 0.86934859  0.71030897  0.35066071]]\n",
      "34 1.15752 [[-0.61451817 -0.3547442  -0.81258869]\n",
      " [ 0.23503841  0.03965637  0.62900245]\n",
      " [ 0.86951274  0.7133795   0.347426  ]]\n",
      "35 1.14876 [[-0.62225533 -0.36363313 -0.79596263]\n",
      " [ 0.23759581  0.04018589  0.62591553]\n",
      " [ 0.8697204   0.71636605  0.34423175]]\n",
      "36 1.14013 [[-0.62995923 -0.37244177 -0.77945012]\n",
      " [ 0.24010444  0.04077508  0.6228177 ]\n",
      " [ 0.86997139  0.71926886  0.34107795]]\n",
      "37 1.13162 [[-0.63762999 -0.38116938 -0.76305169]\n",
      " [ 0.24256486  0.04142284  0.61970949]\n",
      " [ 0.87026209  0.72209126  0.33796489]]\n",
      "38 1.12324 [[-0.64526725 -0.38981575 -0.74676806]\n",
      " [ 0.24498017  0.04212583  0.61659116]\n",
      " [ 0.8705917   0.72483408  0.33489251]]\n",
      "39 1.11497 [[-0.65287101 -0.39838034 -0.7305997 ]\n",
      " [ 0.24735133  0.04288256  0.61346328]\n",
      " [ 0.87095737  0.72750002  0.33186093]]\n",
      "40 1.10682 [[-0.66044104 -0.40686297 -0.71454704]\n",
      " [ 0.24968076  0.04369022  0.61032617]\n",
      " [ 0.87135798  0.7300902   0.32887009]]\n",
      "41 1.0988 [[-0.66797727 -0.41526327 -0.69861054]\n",
      " [ 0.25196958  0.04454713  0.60718042]\n",
      " [ 0.8717913   0.73260695  0.32592005]]\n",
      "42 1.09089 [[-0.67547947 -0.42358106 -0.68279052]\n",
      " [ 0.25421983  0.04545083  0.60402644]\n",
      " [ 0.87225604  0.73505157  0.32301068]]\n",
      "43 1.0831 [[-0.68294764 -0.4318161  -0.66708732]\n",
      " [ 0.25643262  0.04639966  0.60086483]\n",
      " [ 0.87275028  0.73742616  0.32014191]]\n",
      "44 1.07543 [[-0.69038165 -0.43996832 -0.65150112]\n",
      " [ 0.25860977  0.0473913   0.59769601]\n",
      " [ 0.87327284  0.73973197  0.31731355]]\n",
      "45 1.06787 [[-0.69778144 -0.44803756 -0.6360321 ]\n",
      " [ 0.26075229  0.04842417  0.59452063]\n",
      " [ 0.87382191  0.74197096  0.31452549]]\n",
      "46 1.06043 [[-0.70514691 -0.45602381 -0.62068039]\n",
      " [ 0.26286179  0.04949613  0.59133911]\n",
      " [ 0.8743965   0.74414444  0.31177741]]\n",
      "47 1.0531 [[-0.71247804 -0.46392703 -0.60544604]\n",
      " [ 0.26493922  0.05060562  0.58815223]\n",
      " [ 0.87499493  0.74625427  0.30906919]]\n",
      "48 1.04588 [[-0.71977478 -0.47174728 -0.59032905]\n",
      " [ 0.26698601  0.05175066  0.5849604 ]\n",
      " [ 0.87561631  0.74830168  0.30640042]]\n",
      "49 1.03878 [[-0.72703713 -0.47948459 -0.57532942]\n",
      " [ 0.26900306  0.05292977  0.58176422]\n",
      " [ 0.87625915  0.75028843  0.30377081]]\n",
      "50 1.03178 [[-0.73426503 -0.48713911 -0.56044704]\n",
      " [ 0.27099156  0.05414109  0.57856441]\n",
      " [ 0.87692249  0.7522158   0.30118003]]\n",
      "51 1.0249 [[-0.74145854 -0.49471095 -0.54568172]\n",
      " [ 0.27295244  0.05538312  0.57536149]\n",
      " [ 0.8776052   0.75408542  0.29862767]]\n",
      "52 1.01812 [[-0.74861765 -0.50220031 -0.53103328]\n",
      " [ 0.2748867   0.0566542   0.57215613]\n",
      " [ 0.87830633  0.75589859  0.29611334]]\n",
      "53 1.01145 [[-0.75574237 -0.50960743 -0.51650143]\n",
      " [ 0.27679524  0.05795284  0.56894892]\n",
      " [ 0.87902486  0.75765681  0.29363653]]\n",
      "54 1.00489 [[-0.76283276 -0.51693255 -0.50208592]\n",
      " [ 0.27867883  0.05927762  0.56574059]\n",
      " [ 0.87975985  0.75936157  0.29119682]]\n",
      "55 0.99843 [[-0.76988894 -0.52417594 -0.48778641]\n",
      " [ 0.28053838  0.06062695  0.56253171]\n",
      " [ 0.88051051  0.76101404  0.28879368]]\n",
      "56 0.992075 [[-0.7769109  -0.53133792 -0.47360247]\n",
      " [ 0.28237462  0.06199949  0.55932289]\n",
      " [ 0.88127595  0.76261568  0.2864266 ]]\n",
      "57 0.985821 [[-0.78389877 -0.53841883 -0.45953372]\n",
      " [ 0.28418836  0.06339382  0.55611485]\n",
      " [ 0.88205546  0.76416779  0.28409499]]\n",
      "58 0.979668 [[-0.79085261 -0.54541904 -0.44557968]\n",
      " [ 0.28598017  0.06480867  0.55290818]\n",
      " [ 0.8828482   0.76567173  0.2817983 ]]\n",
      "59 0.973615 [[-0.79777253 -0.55233896 -0.43173981]\n",
      " [ 0.28775081  0.06624263  0.5497036 ]\n",
      " [ 0.88365364  0.76712865  0.27953595]]\n",
      "60 0.96766 [[-0.80465865 -0.55917901 -0.4180136 ]\n",
      " [ 0.28950071  0.06769466  0.54650164]\n",
      " [ 0.88447088  0.76854008  0.27730727]]\n",
      "61 0.961801 [[-0.8115111  -0.56593966 -0.40440047]\n",
      " [ 0.29123077  0.06916317  0.54330307]\n",
      " [ 0.88529962  0.76990694  0.27511173]]\n",
      "62 0.956037 [[-0.81833005 -0.57262141 -0.39089978]\n",
      " [ 0.29294121  0.07064732  0.5401085 ]\n",
      " [ 0.88613892  0.77123076  0.27294859]]\n",
      "63 0.950368 [[-0.82511562 -0.57922471 -0.37751091]\n",
      " [ 0.29463285  0.07214569  0.53691852]\n",
      " [ 0.88698858  0.77251256  0.27081719]]\n",
      "64 0.944791 [[-0.83186793 -0.5857501  -0.36423317]\n",
      " [ 0.29630601  0.07365728  0.53373379]\n",
      " [ 0.88784784  0.77375358  0.26871687]]\n",
      "65 0.939304 [[-0.83858722 -0.59219813 -0.35106587]\n",
      " [ 0.29796115  0.075181    0.53055495]\n",
      " [ 0.88871622  0.77495509  0.26664698]]\n",
      "66 0.933908 [[-0.84527355 -0.59856939 -0.33800828]\n",
      " [ 0.29959887  0.07671567  0.52738255]\n",
      " [ 0.88959348  0.7761181   0.26460674]]\n",
      "67 0.9286 [[-0.85192722 -0.60486436 -0.32505965]\n",
      " [ 0.30121934  0.07826045  0.52421731]\n",
      " [ 0.89047891  0.77724391  0.26259553]]\n",
      "68 0.923379 [[-0.85854834 -0.61108375 -0.31221917]\n",
      " [ 0.30282325  0.07981406  0.52105975]\n",
      " [ 0.89137238  0.77833337  0.26061261]]\n",
      "69 0.918244 [[-0.86513716 -0.61722803 -0.2994861 ]\n",
      " [ 0.30441067  0.08137585  0.51791054]\n",
      " [ 0.89227319  0.77938789  0.25865725]]\n",
      "70 0.913192 [[-0.87169379 -0.62329793 -0.28685957]\n",
      " [ 0.30598229  0.08294459  0.51477015]\n",
      " [ 0.89318138  0.78040826  0.25672868]]\n",
      "71 0.908224 [[-0.87821853 -0.62929404 -0.27433875]\n",
      " [ 0.30753809  0.08451961  0.51163936]\n",
      " [ 0.89409626  0.78139579  0.25482628]]\n",
      "72 0.903337 [[-0.8847115  -0.63521701 -0.26192281]\n",
      " [ 0.30907872  0.08609982  0.50851852]\n",
      " [ 0.8950178   0.78235132  0.25294924]]\n",
      "73 0.89853 [[-0.89117301 -0.64106745 -0.24961086]\n",
      " [ 0.31060421  0.08768456  0.50540829]\n",
      " [ 0.89594549  0.78327602  0.25109684]]\n",
      "74 0.893801 [[-0.89760321 -0.64684606 -0.23740202]\n",
      " [ 0.31211501  0.0892728   0.5023092 ]\n",
      " [ 0.89687926  0.78417063  0.24926843]]\n",
      "75 0.889151 [[-0.90400237 -0.6525535  -0.22529539]\n",
      " [ 0.31361127  0.09086394  0.49922183]\n",
      " [ 0.89781868  0.78503639  0.24746323]]\n",
      "76 0.884575 [[-0.91037071 -0.65819049 -0.2132901 ]\n",
      " [ 0.31509334  0.0924571   0.49614659]\n",
      " [ 0.89876372  0.78587413  0.24568047]]\n",
      "77 0.880075 [[-0.91670841 -0.66375768 -0.20138519]\n",
      " [ 0.3165614   0.09405154  0.49308407]\n",
      " [ 0.89971405  0.78668475  0.24391951]]\n",
      "78 0.875648 [[-0.92301577 -0.66925573 -0.18957974]\n",
      " [ 0.31801564  0.09564663  0.49003473]\n",
      " [ 0.9006694   0.78746927  0.24217962]]\n",
      "79 0.871293 [[-0.92929304 -0.67468542 -0.17787282]\n",
      " [ 0.31945637  0.09724156  0.48699906]\n",
      " [ 0.90162975  0.78822845  0.2404601 ]]\n",
      "80 0.867009 [[-0.93554044 -0.68004739 -0.16626349]\n",
      " [ 0.32088369  0.09883579  0.4839775 ]\n",
      " [ 0.9025948   0.78896326  0.23876022]]\n",
      "81 0.862795 [[-0.94175816 -0.68534237 -0.15475079]\n",
      " [ 0.3222979   0.10042859  0.4809705 ]\n",
      " [ 0.90356451  0.78967446  0.23707931]]\n",
      "82 0.858648 [[-0.94794655 -0.69057101 -0.14333378]\n",
      " [ 0.32369903  0.10201945  0.47797856]\n",
      " [ 0.90453857  0.79036301  0.23541671]]\n",
      "83 0.854569 [[-0.95410573 -0.69573408 -0.1320115 ]\n",
      " [ 0.32508746  0.10360757  0.47500202]\n",
      " [ 0.90551704  0.79102951  0.23377174]]\n",
      "84 0.850555 [[-0.96023607 -0.70083225 -0.120783  ]\n",
      " [ 0.32646307  0.10519268  0.47204131]\n",
      " [ 0.90649962  0.79167497  0.23214372]]\n",
      "85 0.846606 [[-0.9663378  -0.70586628 -0.1096473 ]\n",
      " [ 0.3278262   0.10677399  0.46909687]\n",
      " [ 0.90748632  0.79229999  0.23053202]]\n",
      "86 0.842721 [[-0.9724111  -0.71083683 -0.09860346]\n",
      " [ 0.32917696  0.10835113  0.46616897]\n",
      " [ 0.90847701  0.79290539  0.22893596]]\n",
      "87 0.838897 [[-0.97845626 -0.71574461 -0.0876505 ]\n",
      " [ 0.3305155   0.10992352  0.46325806]\n",
      " [ 0.90947157  0.79349184  0.22735494]]\n",
      "88 0.835134 [[-0.98447359 -0.72059035 -0.07678747]\n",
      " [ 0.33184192  0.11149073  0.46036443]\n",
      " [ 0.91046995  0.79406005  0.22578835]]\n",
      "89 0.831432 [[-0.99046326 -0.72537476 -0.0660134 ]\n",
      " [ 0.33315632  0.11305232  0.45748845]\n",
      " [ 0.91147202  0.79461074  0.22423558]]\n",
      "90 0.827788 [[-0.99642557 -0.73009855 -0.05532734]\n",
      " [ 0.3344588   0.11460783  0.45463043]\n",
      " [ 0.91247767  0.79514456  0.22269605]]\n",
      "91 0.824201 [[-1.0023607  -0.73476237 -0.04472832]\n",
      " [ 0.3357496   0.11615682  0.45179066]\n",
      " [ 0.91348702  0.79566211  0.22116916]]\n",
      "92 0.820671 [[-1.00826907 -0.73936695 -0.0342154 ]\n",
      " [ 0.33702865  0.117699    0.44896942]\n",
      " [ 0.91449976  0.79616416  0.21965435]]\n",
      "93 0.817197 [[-1.01415074 -0.74391305 -0.02378763]\n",
      " [ 0.33829626  0.11923384  0.44616699]\n",
      " [ 0.91551614  0.79665107  0.21815108]]\n",
      "94 0.813777 [[-1.02000606 -0.74840128 -0.01344404]\n",
      " [ 0.33955219  0.12076122  0.44338366]\n",
      " [ 0.91653574  0.79712373  0.21665883]]\n",
      "95 0.81041 [[-1.02583528 -0.75283241 -0.00318371]\n",
      " [ 0.34079698  0.12228048  0.44061962]\n",
      " [ 0.91755891  0.79758233  0.21517701]]\n",
      "96 0.807096 [[-1.03163862 -0.75720704  0.00699431]\n",
      " [ 0.34203026  0.12379171  0.43787512]\n",
      " [ 0.91858524  0.79802787  0.21370517]]\n",
      "97 0.803833 [[-1.03741634 -0.76152593  0.01709095]\n",
      " [ 0.34325251  0.12529416  0.43515041]\n",
      " [ 0.91961503  0.79846042  0.21224281]]\n",
      "98 0.80062 [[-1.04316878 -0.76578969  0.02710713]\n",
      " [ 0.34446344  0.12678802  0.43244562]\n",
      " [ 0.92064786  0.79888093  0.21078941]]\n",
      "99 0.797457 [[-1.04889607 -0.76999909  0.03704378]\n",
      " [ 0.34566358  0.12827253  0.42976099]\n",
      " [ 0.92168421  0.79928946  0.20934457]]\n",
      "100 0.794342 [[-1.05459845 -0.77415466  0.04690181]\n",
      " [ 0.34685251  0.12974796  0.42709666]\n",
      " [ 0.92272353  0.79968697  0.20790777]]\n",
      "101 0.791275 [[-1.06027627 -0.77825719  0.05668213]\n",
      " [ 0.34803066  0.13121364  0.42445284]\n",
      " [ 0.92376614  0.8000735   0.20647863]]\n",
      "102 0.788254 [[-1.06592965 -0.78230733  0.06638564]\n",
      " [ 0.34919795  0.13266957  0.42182961]\n",
      " [ 0.9248119   0.80044967  0.20505667]]\n",
      "103 0.785278 [[-1.07155895 -0.78630567  0.07601324]\n",
      " [ 0.35035443  0.13411556  0.41922715]\n",
      " [ 0.9258607   0.800816    0.20364153]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 0.782348 [[-1.07716429 -0.79025286  0.08556581]\n",
      " [ 0.35150033  0.13555129  0.41664556]\n",
      " [ 0.92691278  0.80117267  0.20223278]]\n",
      "105 0.779461 [[-1.08274603 -0.79414958  0.09504423]\n",
      " [ 0.3526355   0.13697672  0.41408497]\n",
      " [ 0.92796785  0.80152035  0.20083006]]\n",
      "106 0.776617 [[-1.08830428 -0.79799646  0.10444938]\n",
      " [ 0.35376018  0.13839157  0.41154546]\n",
      " [ 0.92902607  0.8018592   0.19943298]]\n",
      "107 0.773816 [[-1.09383941 -0.80179411  0.11378212]\n",
      " [ 0.35487431  0.13979581  0.4090271 ]\n",
      " [ 0.93008733  0.80218977  0.1980412 ]]\n",
      "108 0.771055 [[-1.09935153 -0.80554318  0.12304331]\n",
      " [ 0.35597801  0.14118923  0.40652999]\n",
      " [ 0.93115163  0.80251229  0.19665438]]\n",
      "109 0.768335 [[-1.10484099 -0.80924428  0.1322338 ]\n",
      " [ 0.35707134  0.14257169  0.40405422]\n",
      " [ 0.93221897  0.80282712  0.19527219]]\n",
      "110 0.765656 [[-1.11030793 -0.81289798  0.14135441]\n",
      " [ 0.35815439  0.14394312  0.40159976]\n",
      " [ 0.93328941  0.80313462  0.19389428]]\n",
      "111 0.763015 [[-1.11575258 -0.8165049   0.150406  ]\n",
      " [ 0.35922709  0.14530341  0.39916676]\n",
      " [ 0.93436277  0.80343509  0.19252042]]\n",
      "112 0.760412 [[-1.12117517 -0.82006568  0.15938939]\n",
      " [ 0.3602896   0.14665249  0.39675519]\n",
      " [ 0.93543917  0.80372882  0.19115026]]\n",
      "113 0.757847 [[-1.12657595 -0.82358086  0.16830538]\n",
      " [ 0.36134198  0.14799023  0.39436507]\n",
      " [ 0.93651861  0.80401611  0.18978354]]\n",
      "114 0.755318 [[-1.13195515 -0.82705104  0.17715478]\n",
      " [ 0.36238426  0.14931661  0.39199641]\n",
      " [ 0.93760097  0.80429727  0.18841998]]\n",
      "115 0.752825 [[-1.13731301 -0.83047682  0.18593839]\n",
      " [ 0.36341655  0.1506315   0.38964921]\n",
      " [ 0.93868637  0.80457252  0.18705933]]\n",
      "116 0.750368 [[-1.14264965 -0.83385879  0.194657  ]\n",
      " [ 0.36443886  0.15193492  0.38732347]\n",
      " [ 0.93977469  0.80484217  0.18570134]]\n",
      "117 0.747946 [[-1.14796531 -0.83719748  0.20331138]\n",
      " [ 0.36545125  0.15322681  0.38501921]\n",
      " [ 0.94086599  0.8051064   0.18434583]]\n",
      "118 0.745557 [[-1.15326035 -0.84049344  0.21190232]\n",
      " [ 0.36645377  0.15450715  0.38273636]\n",
      " [ 0.94196022  0.8053655   0.18299252]]\n",
      "119 0.743202 [[-1.15853477 -0.8437472   0.22043058]\n",
      " [ 0.36744651  0.15577586  0.3804749 ]\n",
      " [ 0.94305736  0.80561966  0.18164122]]\n",
      "120 0.740879 [[-1.16378891 -0.84695935  0.2288969 ]\n",
      " [ 0.36842948  0.15703295  0.3782348 ]\n",
      " [ 0.94415742  0.80586904  0.18029174]]\n",
      "121 0.738588 [[-1.16902292 -0.85013044  0.23730204]\n",
      " [ 0.3694028   0.15827844  0.37601602]\n",
      " [ 0.94526041  0.80611396  0.17894389]]\n",
      "122 0.736329 [[-1.17423701 -0.85326099  0.24564673]\n",
      " [ 0.37036651  0.15951224  0.37381852]\n",
      " [ 0.94636631  0.80635446  0.17759748]]\n",
      "123 0.7341 [[-1.17943144 -0.85635149  0.2539317 ]\n",
      " [ 0.37132055  0.16073456  0.37164217]\n",
      " [ 0.94747496  0.80659097  0.17625231]]\n",
      "124 0.731902 [[-1.18460643 -0.85940248  0.26215768]\n",
      " [ 0.37226519  0.16194513  0.36948696]\n",
      " [ 0.94858658  0.80682337  0.17490827]]\n",
      "125 0.729733 [[-1.18976212 -0.86241448  0.27032536]\n",
      " [ 0.37320033  0.16314416  0.36735278]\n",
      " [ 0.94970101  0.80705202  0.17356518]]\n",
      "126 0.727593 [[-1.19489872 -0.86538798  0.27843544]\n",
      " [ 0.37412608  0.1643316   0.36523959]\n",
      " [ 0.9508183   0.80727702  0.1722229 ]]\n",
      "127 0.725482 [[-1.20001638 -0.8683235   0.28648862]\n",
      " [ 0.37504253  0.16550747  0.36314726]\n",
      " [ 0.95193845  0.80749851  0.17088129]]\n",
      "128 0.723399 [[-1.20511532 -0.87122154  0.2944856 ]\n",
      " [ 0.37594965  0.16667187  0.36107576]\n",
      " [ 0.95306134  0.80771667  0.16954026]]\n",
      "129 0.721343 [[-1.21019578 -0.87408257  0.30242702]\n",
      " [ 0.37684754  0.16782482  0.35902491]\n",
      " [ 0.95418698  0.80793166  0.16819963]]\n",
      "130 0.719314 [[-1.21525788 -0.87690705  0.31031358]\n",
      " [ 0.37773633  0.16896628  0.35699466]\n",
      " [ 0.95531547  0.8081435   0.16685933]]\n",
      "131 0.717311 [[-1.22030175 -0.87969553  0.31814593]\n",
      " [ 0.37861601  0.17009637  0.35498488]\n",
      " [ 0.95644671  0.80835235  0.16551924]]\n",
      "132 0.715334 [[-1.22532773 -0.88244838  0.32592472]\n",
      " [ 0.37948653  0.17121522  0.35299549]\n",
      " [ 0.95758057  0.80855846  0.16417927]]\n",
      "133 0.713382 [[-1.23033583 -0.88516611  0.33365062]\n",
      " [ 0.38034827  0.17232263  0.35102633]\n",
      " [ 0.95871729  0.80876172  0.16283931]]\n",
      "134 0.711456 [[-1.23532641 -0.88784915  0.34132421]\n",
      " [ 0.38120091  0.17341901  0.34907731]\n",
      " [ 0.95985651  0.80896246  0.16149929]]\n",
      "135 0.709553 [[-1.24029946 -0.89049804  0.34894615]\n",
      " [ 0.38204482  0.17450412  0.3471483 ]\n",
      " [ 0.96099854  0.80916053  0.16015916]]\n",
      "136 0.707675 [[-1.24525535 -0.89311314  0.35651708]\n",
      " [ 0.38287985  0.17557822  0.34523916]\n",
      " [ 0.96214312  0.80935627  0.1588188 ]]\n",
      "137 0.70582 [[-1.25019407 -0.89569485  0.36403757]\n",
      " [ 0.38370624  0.17664124  0.34334978]\n",
      " [ 0.96329045  0.80954957  0.15747818]]\n",
      "138 0.703988 [[-1.25511587 -0.89824367  0.37150824]\n",
      " [ 0.38452384  0.17769346  0.34147999]\n",
      " [ 0.96444029  0.80974072  0.15613721]]\n",
      "139 0.702179 [[-1.26002097 -0.90075999  0.37892967]\n",
      " [ 0.38533297  0.17873463  0.33962965]\n",
      " [ 0.9655928   0.80992955  0.15479587]]\n",
      "140 0.700392 [[-1.26490951 -0.90324426  0.38630244]\n",
      " [ 0.3861334   0.17976519  0.33779866]\n",
      " [ 0.96674776  0.81011641  0.15345408]]\n",
      "141 0.698626 [[-1.26978159 -0.90569687  0.39362717]\n",
      " [ 0.38692552  0.1807849   0.33598685]\n",
      " [ 0.9679054   0.81030107  0.15211183]]\n",
      "142 0.696882 [[-1.27463746 -0.90811825  0.40090439]\n",
      " [ 0.38770902  0.18179417  0.33419406]\n",
      " [ 0.96906537  0.81048387  0.15076904]]\n",
      "143 0.695159 [[-1.27947724 -0.91050881  0.40813467]\n",
      " [ 0.38848436  0.18279274  0.33242017]\n",
      " [ 0.97022802  0.81066459  0.1494257 ]]\n",
      "144 0.693456 [[-1.28430104 -0.91286886  0.41531858]\n",
      " [ 0.38925123  0.18378101  0.33066502]\n",
      " [ 0.97139293  0.81084359  0.14808178]]\n",
      "145 0.691774 [[-1.28910911 -0.91519892  0.42245665]\n",
      " [ 0.39001     0.18475881  0.32892844]\n",
      " [ 0.97256041  0.81102061  0.14673723]]\n",
      "146 0.690111 [[-1.29390156 -0.91749924  0.42954946]\n",
      " [ 0.39076054  0.18572645  0.32721028]\n",
      " [ 0.97373021  0.81119603  0.14539205]]\n",
      "147 0.688468 [[-1.29867852 -0.9197703   0.4365975 ]\n",
      " [ 0.39150304  0.18668382  0.32551041]\n",
      " [ 0.97490245  0.8113696   0.14404622]]\n",
      "148 0.686844 [[-1.30344021 -0.92201245  0.44360131]\n",
      " [ 0.39223745  0.1876312   0.32382861]\n",
      " [ 0.97607702  0.81154156  0.14269969]]\n",
      "149 0.685239 [[-1.30818665 -0.92422605  0.4505614 ]\n",
      " [ 0.39296395  0.18856855  0.32216477]\n",
      " [ 0.97725397  0.81171179  0.14135249]]\n",
      "150 0.683652 [[-1.31291819 -0.92641145  0.45747831]\n",
      " [ 0.39368239  0.18949614  0.32051873]\n",
      " [ 0.97843307  0.81188059  0.14000461]]\n",
      "151 0.682083 [[-1.31763482 -0.92856908  0.46435252]\n",
      " [ 0.39439321  0.19041377  0.3188903 ]\n",
      " [ 0.97961462  0.81204766  0.13865601]]\n",
      "152 0.680532 [[-1.32233667 -0.93069923  0.47118455]\n",
      " [ 0.39509612  0.19132182  0.31727934]\n",
      " [ 0.9807983   0.8122133   0.13730669]]\n",
      "153 0.678998 [[-1.32702398 -0.93280226  0.47797489]\n",
      " [ 0.39579132  0.19222027  0.31568569]\n",
      " [ 0.9819842   0.81237739  0.13595669]]\n",
      "154 0.677482 [[-1.33169687 -0.93487853  0.48472401]\n",
      " [ 0.39647895  0.19310918  0.31410918]\n",
      " [ 0.9831723   0.81253999  0.13460599]]\n",
      "155 0.675982 [[-1.33635545 -0.93692833  0.49143237]\n",
      " [ 0.39715898  0.19398874  0.31254959]\n",
      " [ 0.98436254  0.81270117  0.13325457]]\n",
      "156 0.674498 [[-1.34099984 -0.93895203  0.49810046]\n",
      " [ 0.3978315   0.19485901  0.31100681]\n",
      " [ 0.98555493  0.81286091  0.13190246]]\n",
      "157 0.673031 [[-1.34563017 -0.94094998  0.50472879]\n",
      " [ 0.39849654  0.19572008  0.3094807 ]\n",
      " [ 0.98674941  0.81301922  0.13054968]]\n",
      "158 0.67158 [[-1.35024667 -0.94292247  0.51131773]\n",
      " [ 0.39915416  0.19657211  0.30797106]\n",
      " [ 0.98794591  0.81317621  0.12919624]]\n",
      "159 0.670144 [[-1.35484934 -0.94486982  0.5178678 ]\n",
      " [ 0.39980462  0.19741501  0.3064777 ]\n",
      " [ 0.98914456  0.81333166  0.12784213]]\n",
      "160 0.668723 [[-1.35943842 -0.94679236  0.52437943]\n",
      " [ 0.40044761  0.19824921  0.30500048]\n",
      " [ 0.990345    0.81348598  0.12648737]]\n",
      "161 0.667318 [[-1.36401403 -0.94869041  0.53085303]\n",
      " [ 0.40108359  0.19907446  0.30353925]\n",
      " [ 0.99154758  0.81363875  0.12513199]]\n",
      "162 0.665928 [[-1.36857629 -0.95056427  0.53728908]\n",
      " [ 0.40171236  0.19989115  0.3020938 ]\n",
      " [ 0.99275202  0.81379032  0.12377599]]\n",
      "163 0.664552 [[-1.3731252  -0.95241421  0.543688  ]\n",
      " [ 0.40233415  0.20069918  0.30066398]\n",
      " [ 0.99395847  0.81394053  0.1224194 ]]\n",
      "164 0.66319 [[-1.37766111 -0.95424056  0.5500502 ]\n",
      " [ 0.40294883  0.20149882  0.29924965]\n",
      " [ 0.99516666  0.81408948  0.12106226]]\n",
      "165 0.661842 [[-1.38218391 -0.9560436   0.5563761 ]\n",
      " [ 0.40355673  0.20228997  0.29785061]\n",
      " [ 0.99637681  0.814237    0.11970456]]\n",
      "166 0.660508 [[-1.38669384 -0.95782363  0.56266612]\n",
      " [ 0.40415761  0.20307297  0.29646674]\n",
      " [ 0.99758863  0.81438339  0.11834634]]\n",
      "167 0.659188 [[-1.39119101 -0.95958096  0.56892061]\n",
      " [ 0.40475187  0.20384762  0.2950978 ]\n",
      " [ 0.99880242  0.81452835  0.1169876 ]]\n",
      "168 0.657881 [[-1.39567554 -0.96131581  0.57514006]\n",
      " [ 0.40533921  0.20461437  0.2937437 ]\n",
      " [ 1.00001776  0.81467223  0.11562839]]\n",
      "169 0.656587 [[-1.40014756 -0.96302855  0.58132482]\n",
      " [ 0.40592009  0.20537291  0.29240426]\n",
      " [ 1.00123501  0.81481457  0.11426876]]\n",
      "170 0.655306 [[-1.40460718 -0.96471936  0.58747524]\n",
      " [ 0.40649417  0.20612383  0.29107928]\n",
      " [ 1.0024538   0.81495589  0.11290867]]\n",
      "171 0.654038 [[-1.40905452 -0.96638852  0.59359175]\n",
      " [ 0.40706187  0.20686677  0.28976864]\n",
      " [ 1.00367439  0.81509578  0.11154821]]\n",
      "172 0.652782 [[-1.4134897  -0.96803635  0.5996747 ]\n",
      " [ 0.40762302  0.20760208  0.28847218]\n",
      " [ 1.00489652  0.81523448  0.11018738]]\n",
      "173 0.651538 [[-1.41791284 -0.96966308  0.60572451]\n",
      " [ 0.40817776  0.20832983  0.28718969]\n",
      " [ 1.0061202   0.81537193  0.10882622]]\n",
      "174 0.650306 [[-1.42232394 -0.97126895  0.61174154]\n",
      " [ 0.40872622  0.20905003  0.28592107]\n",
      " [ 1.00734556  0.81550813  0.10746475]]\n",
      "175 0.649086 [[-1.42672324 -0.97285426  0.61772609]\n",
      " [ 0.40926832  0.20976287  0.28466612]\n",
      " [ 1.00857234  0.81564307  0.106103  ]]\n",
      "176 0.647878 [[-1.43111074 -0.97441924  0.62367857]\n",
      " [ 0.40980425  0.21046835  0.28342471]\n",
      " [ 1.00980067  0.81577671  0.10474101]]\n",
      "177 0.646681 [[-1.43548667 -0.97596407  0.62959933]\n",
      " [ 0.41033399  0.21116668  0.28219664]\n",
      " [ 1.01103044  0.81590915  0.10337881]]\n",
      "178 0.645495 [[-1.43985105 -0.97748911  0.63548869]\n",
      " [ 0.41085771  0.21185781  0.28098181]\n",
      " [ 1.01226175  0.81604028  0.10201641]]\n",
      "179 0.644321 [[-1.44420397 -0.97899449  0.64134705]\n",
      " [ 0.41137525  0.21254203  0.27978003]\n",
      " [ 1.01349425  0.81617028  0.10065387]]\n",
      "180 0.643157 [[-1.44854558 -0.98048055  0.64717472]\n",
      " [ 0.41188699  0.21321915  0.27859116]\n",
      " [ 1.01472831  0.81629884  0.09929122]]\n",
      "181 0.642004 [[-1.45287597 -0.98194742  0.65297198]\n",
      " [ 0.41239271  0.21388955  0.27741504]\n",
      " [ 1.01596367  0.81642628  0.09792846]]\n",
      "182 0.640862 [[-1.45719516 -0.9833954   0.65873921]\n",
      " [ 0.41289261  0.21455315  0.27625155]\n",
      " [ 1.01720035  0.8165524   0.09656567]]\n",
      "183 0.639729 [[-1.46150339 -0.98482472  0.66447675]\n",
      " [ 0.4133867   0.21521007  0.2751005 ]\n",
      " [ 1.01843834  0.81667727  0.09520284]]\n",
      "184 0.638607 [[-1.46580064 -0.98623556  0.67018491]\n",
      " [ 0.41387507  0.21586044  0.27396178]\n",
      " [ 1.01967752  0.81680089  0.09384004]]\n",
      "185 0.637496 [[-1.47008705 -0.98762816  0.67586398]\n",
      " [ 0.41435781  0.21650425  0.27283522]\n",
      " [ 1.02091801  0.8169232   0.09247728]]\n",
      "186 0.636393 [[-1.47436273 -0.98900276  0.68151426]\n",
      " [ 0.41483486  0.21714173  0.27172068]\n",
      " [ 1.02215958  0.81704432  0.0911146 ]]\n",
      "187 0.635301 [[-1.4786278  -0.99035954  0.68713611]\n",
      " [ 0.41530642  0.21777284  0.27061799]\n",
      " [ 1.02340233  0.81716412  0.089752  ]]\n",
      "188 0.634218 [[-1.48288226 -0.99169874  0.69272983]\n",
      " [ 0.41577253  0.21839768  0.26952705]\n",
      " [ 1.02464628  0.81728262  0.08838955]]\n",
      "189 0.633144 [[-1.48712635 -0.99302053  0.69829565]\n",
      " [ 0.41623309  0.21901646  0.2684477 ]\n",
      " [ 1.0258913   0.81739992  0.08702726]]\n",
      "190 0.63208 [[-1.49135995 -0.99432516  0.70383394]\n",
      " [ 0.41668838  0.21962906  0.26737979]\n",
      " [ 1.0271374   0.81751585  0.08566517]]\n",
      "191 0.631025 [[-1.4955833  -0.9956128   0.70934492]\n",
      " [ 0.41713834  0.22023574  0.26632318]\n",
      " [ 1.02838457  0.81763053  0.08430333]]\n",
      "192 0.629979 [[-1.49979651 -0.99688369  0.71482897]\n",
      " [ 0.41758299  0.22083651  0.26527774]\n",
      " [ 1.02963269  0.81774396  0.08294175]]\n",
      "193 0.628941 [[-1.50399959 -0.99813801  0.72028631]\n",
      " [ 0.41802248  0.22143137  0.26424336]\n",
      " [ 1.03088188  0.81785601  0.08158047]]\n",
      "194 0.627913 [[-1.50819266 -0.99937588  0.72571725]\n",
      " [ 0.41845679  0.2220206   0.26321983]\n",
      " [ 1.03213191  0.81796694  0.0802195 ]]\n",
      "195 0.626893 [[-1.51237571 -1.0005976   0.73112202]\n",
      " [ 0.4188861   0.22260402  0.26220709]\n",
      " [ 1.03338301  0.81807643  0.07885891]]\n",
      "196 0.625881 [[-1.51654887 -1.00180328  0.73650092]\n",
      " [ 0.4193103   0.22318192  0.26120499]\n",
      " [ 1.03463495  0.81818473  0.07749871]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 0.624877 [[-1.52071226 -1.00299311  0.74185425]\n",
      " [ 0.41972956  0.22375423  0.2602134 ]\n",
      " [ 1.03588784  0.81829166  0.07613894]]\n",
      "198 0.623882 [[-1.52486598 -1.00416732  0.74718219]\n",
      " [ 0.42014381  0.22432119  0.25923219]\n",
      " [ 1.03714144  0.81839734  0.07477961]]\n",
      "199 0.622895 [[-1.52901006 -1.00532603  0.7524851 ]\n",
      " [ 0.4205533   0.22488269  0.25826123]\n",
      " [ 1.038396    0.81850165  0.07342077]]\n",
      "200 0.621915 [[-1.53314459 -1.00646949  0.75776315]\n",
      " [ 0.42095786  0.22543894  0.25730041]\n",
      " [ 1.03965127  0.81860471  0.07206244]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normalized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2.7921e+12 \n",
      "Prediction:\n",
      " [[-1177925.375]\n",
      " [-2371896.5  ]\n",
      " [-1865760.375]\n",
      " [-1307713.75 ]\n",
      " [-1541312.875]\n",
      " [-1554291.75 ]\n",
      " [-1424517.5  ]\n",
      " [-1813858.75 ]]\n",
      "1 Cost:  3.06763e+27 \n",
      "Prediction:\n",
      " [[  3.90690358e+13]\n",
      " [  7.86499780e+13]\n",
      " [  6.18710927e+13]\n",
      " [  4.33713054e+13]\n",
      " [  5.11154040e+13]\n",
      " [  5.15456306e+13]\n",
      " [  4.72433568e+13]\n",
      " [  6.01501823e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      " [[ -1.29499558e+21]\n",
      " [ -2.60695931e+21]\n",
      " [ -2.05080064e+21]\n",
      " [ -1.43760037e+21]\n",
      " [ -1.69428880e+21]\n",
      " [ -1.70854931e+21]\n",
      " [ -1.56594466e+21]\n",
      " [ -1.99375875e+21]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      " [[  4.29243752e+28]\n",
      " [  8.64111747e+28]\n",
      " [  6.79765482e+28]\n",
      " [  4.76511996e+28]\n",
      " [  5.61594825e+28]\n",
      " [  5.66321678e+28]\n",
      " [  5.19053434e+28]\n",
      " [  6.60858166e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      " [[ -1.42278616e+36]\n",
      " [ -2.86421470e+36]\n",
      " [ -2.25317431e+36]\n",
      " [ -1.57946318e+36]\n",
      " [ -1.86148184e+36]\n",
      " [ -1.87714953e+36]\n",
      " [ -1.72047251e+36]\n",
      " [ -2.19050341e+36]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      " [[ inf]\n",
      " [ inf]\n",
      " [ inf]\n",
      " [ inf]\n",
      " [ inf]\n",
      " [ inf]\n",
      " [ inf]\n",
      " [ inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "11 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "12 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "13 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "14 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "15 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "16 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "17 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "18 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "19 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "20 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "21 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "22 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "23 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "24 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "25 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "26 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "27 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "28 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "29 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "30 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "31 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "32 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "33 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "34 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "35 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "36 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "37 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "38 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "39 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "40 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "41 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "42 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "43 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "44 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "45 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "46 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "47 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "48 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "49 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "50 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "51 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "52 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "53 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "54 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "55 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "56 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "57 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "58 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "59 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "60 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "61 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "62 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "63 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "64 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "65 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "66 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "67 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "68 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "69 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "70 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "71 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "72 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "73 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "74 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "75 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "76 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "77 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "78 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "79 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "80 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "81 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "82 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "83 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "84 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "85 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "86 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "87 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "88 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "89 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "90 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "91 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "92 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "93 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "94 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "95 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "96 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "97 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "98 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "99 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "100 Cost:  nan \n",
      "Prediction:\n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized inputs (min-max scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1.65831 \n",
      "Prediction:\n",
      " [[ 3.59851742]\n",
      " [ 2.21108341]\n",
      " [ 1.76637876]\n",
      " [ 1.21805656]\n",
      " [ 1.71157539]\n",
      " [ 1.50633109]\n",
      " [ 0.24619541]\n",
      " [-0.33685863]]\n",
      "1 Cost:  1.65821 \n",
      "Prediction:\n",
      " [[ 3.59845567]\n",
      " [ 2.21102715]\n",
      " [ 1.76633239]\n",
      " [ 1.21802044]\n",
      " [ 1.71153212]\n",
      " [ 1.50628972]\n",
      " [ 0.24616954]\n",
      " [-0.33688283]]\n",
      "2 Cost:  1.65811 \n",
      "Prediction:\n",
      " [[ 3.59839344]\n",
      " [ 2.21097088]\n",
      " [ 1.76628518]\n",
      " [ 1.2179842 ]\n",
      " [ 1.71148896]\n",
      " [ 1.50624824]\n",
      " [ 0.24614364]\n",
      " [-0.33690709]]\n",
      "3 Cost:  1.65801 \n",
      "Prediction:\n",
      " [[ 3.59833193]\n",
      " [ 2.21091461]\n",
      " [ 1.76623857]\n",
      " [ 1.21794832]\n",
      " [ 1.71144569]\n",
      " [ 1.50620663]\n",
      " [ 0.24611774]\n",
      " [-0.33693132]]\n",
      "4 Cost:  1.65791 \n",
      "Prediction:\n",
      " [[ 3.59827018]\n",
      " [ 2.21085858]\n",
      " [ 1.7661922 ]\n",
      " [ 1.2179122 ]\n",
      " [ 1.71140265]\n",
      " [ 1.50616527]\n",
      " [ 0.24609184]\n",
      " [-0.33695555]]\n",
      "5 Cost:  1.6578 \n",
      "Prediction:\n",
      " [[ 3.59820843]\n",
      " [ 2.21080232]\n",
      " [ 1.76614511]\n",
      " [ 1.21787608]\n",
      " [ 1.71135938]\n",
      " [ 1.5061239 ]\n",
      " [ 0.24606594]\n",
      " [-0.33697981]]\n",
      "6 Cost:  1.6577 \n",
      "Prediction:\n",
      " [[ 3.59814692]\n",
      " [ 2.21074653]\n",
      " [ 1.7660985 ]\n",
      " [ 1.21784019]\n",
      " [ 1.71131635]\n",
      " [ 1.50608253]\n",
      " [ 0.24604008]\n",
      " [-0.33700401]]\n",
      "7 Cost:  1.6576 \n",
      "Prediction:\n",
      " [[ 3.59808517]\n",
      " [ 2.21069026]\n",
      " [ 1.76605177]\n",
      " [ 1.21780396]\n",
      " [ 1.71127319]\n",
      " [ 1.50604105]\n",
      " [ 0.24601418]\n",
      " [-0.33702826]]\n",
      "8 Cost:  1.6575 \n",
      "Prediction:\n",
      " [[ 3.59802341]\n",
      " [ 2.21063423]\n",
      " [ 1.76600516]\n",
      " [ 1.21776783]\n",
      " [ 1.71123004]\n",
      " [ 1.50599968]\n",
      " [ 0.24598831]\n",
      " [-0.33705249]]\n",
      "9 Cost:  1.6574 \n",
      "Prediction:\n",
      " [[ 3.59796214]\n",
      " [ 2.21057844]\n",
      " [ 1.76595855]\n",
      " [ 1.21773195]\n",
      " [ 1.71118701]\n",
      " [ 1.5059582 ]\n",
      " [ 0.24596241]\n",
      " [-0.33707675]]\n",
      "10 Cost:  1.65729 \n",
      "Prediction:\n",
      " [[ 3.59790015]\n",
      " [ 2.21052194]\n",
      " [ 1.76591182]\n",
      " [ 1.21769571]\n",
      " [ 1.71114373]\n",
      " [ 1.5059166 ]\n",
      " [ 0.24593654]\n",
      " [-0.33710098]]\n",
      "11 Cost:  1.65719 \n",
      "Prediction:\n",
      " [[ 3.59783888]\n",
      " [ 2.21046638]\n",
      " [ 1.76586521]\n",
      " [ 1.21765971]\n",
      " [ 1.7111007 ]\n",
      " [ 1.50587547]\n",
      " [ 0.24591063]\n",
      " [-0.33712521]]\n",
      "12 Cost:  1.65709 \n",
      "Prediction:\n",
      " [[ 3.59777737]\n",
      " [ 2.21041036]\n",
      " [ 1.7658186 ]\n",
      " [ 1.21762371]\n",
      " [ 1.71105754]\n",
      " [ 1.50583398]\n",
      " [ 0.24588481]\n",
      " [-0.33714944]]\n",
      "13 Cost:  1.65699 \n",
      "Prediction:\n",
      " [[ 3.59771585]\n",
      " [ 2.21035433]\n",
      " [ 1.76577175]\n",
      " [ 1.21758759]\n",
      " [ 1.71101451]\n",
      " [ 1.5057925 ]\n",
      " [ 0.24585892]\n",
      " [-0.33717364]]\n",
      "14 Cost:  1.65689 \n",
      "Prediction:\n",
      " [[ 3.5976541 ]\n",
      " [ 2.2102983 ]\n",
      " [ 1.76572537]\n",
      " [ 1.21755171]\n",
      " [ 1.71097136]\n",
      " [ 1.50575125]\n",
      " [ 0.24583304]\n",
      " [-0.33719787]]\n",
      "15 Cost:  1.65679 \n",
      "Prediction:\n",
      " [[ 3.59759235]\n",
      " [ 2.21024227]\n",
      " [ 1.76567876]\n",
      " [ 1.21751559]\n",
      " [ 1.71092832]\n",
      " [ 1.50570977]\n",
      " [ 0.24580719]\n",
      " [-0.3372221 ]]\n",
      "16 Cost:  1.65668 \n",
      "Prediction:\n",
      " [[ 3.59753084]\n",
      " [ 2.21018624]\n",
      " [ 1.76563215]\n",
      " [ 1.21747947]\n",
      " [ 1.71088517]\n",
      " [ 1.5056684 ]\n",
      " [ 0.24578133]\n",
      " [-0.3372463 ]]\n",
      "17 Cost:  1.65658 \n",
      "Prediction:\n",
      " [[ 3.59746933]\n",
      " [ 2.21013021]\n",
      " [ 1.7655853 ]\n",
      " [ 1.21744359]\n",
      " [ 1.71084213]\n",
      " [ 1.50562716]\n",
      " [ 0.24575548]\n",
      " [-0.33727053]]\n",
      "18 Cost:  1.65648 \n",
      "Prediction:\n",
      " [[ 3.59740758]\n",
      " [ 2.21007419]\n",
      " [ 1.76553893]\n",
      " [ 1.21740746]\n",
      " [ 1.71079898]\n",
      " [ 1.50558567]\n",
      " [ 0.24572957]\n",
      " [-0.33729476]]\n",
      "19 Cost:  1.65638 \n",
      "Prediction:\n",
      " [[ 3.59734607]\n",
      " [ 2.21001816]\n",
      " [ 1.7654922 ]\n",
      " [ 1.21737146]\n",
      " [ 1.71075583]\n",
      " [ 1.5055443 ]\n",
      " [ 0.24570374]\n",
      " [-0.33731899]]\n",
      "20 Cost:  1.65628 \n",
      "Prediction:\n",
      " [[ 3.59728479]\n",
      " [ 2.20996237]\n",
      " [ 1.76544535]\n",
      " [ 1.21733534]\n",
      " [ 1.71071279]\n",
      " [ 1.50550282]\n",
      " [ 0.24567786]\n",
      " [-0.33734322]]\n",
      "21 Cost:  1.65617 \n",
      "Prediction:\n",
      " [[ 3.59722304]\n",
      " [ 2.2099061 ]\n",
      " [ 1.76539874]\n",
      " [ 1.21729934]\n",
      " [ 1.71066976]\n",
      " [ 1.50546145]\n",
      " [ 0.24565198]\n",
      " [-0.33736742]]\n",
      "22 Cost:  1.65607 \n",
      "Prediction:\n",
      " [[ 3.59716129]\n",
      " [ 2.20984983]\n",
      " [ 1.76535213]\n",
      " [ 1.21726334]\n",
      " [ 1.7106266 ]\n",
      " [ 1.50542021]\n",
      " [ 0.24562612]\n",
      " [-0.33739164]]\n",
      "23 Cost:  1.65597 \n",
      "Prediction:\n",
      " [[ 3.59709978]\n",
      " [ 2.20979404]\n",
      " [ 1.76530552]\n",
      " [ 1.21722722]\n",
      " [ 1.71058345]\n",
      " [ 1.50537872]\n",
      " [ 0.24560027]\n",
      " [-0.33741587]]\n",
      "24 Cost:  1.65587 \n",
      "Prediction:\n",
      " [[ 3.59703803]\n",
      " [ 2.20973802]\n",
      " [ 1.76525891]\n",
      " [ 1.21719122]\n",
      " [ 1.71054041]\n",
      " [ 1.50533736]\n",
      " [ 0.24557441]\n",
      " [-0.33744007]]\n",
      "25 Cost:  1.65577 \n",
      "Prediction:\n",
      " [[ 3.59697676]\n",
      " [ 2.20968199]\n",
      " [ 1.7652123 ]\n",
      " [ 1.21715522]\n",
      " [ 1.71049738]\n",
      " [ 1.50529599]\n",
      " [ 0.24554853]\n",
      " [-0.3374643 ]]\n",
      "26 Cost:  1.65567 \n",
      "Prediction:\n",
      " [[ 3.59691477]\n",
      " [ 2.2096262 ]\n",
      " [ 1.76516557]\n",
      " [ 1.21711898]\n",
      " [ 1.71045423]\n",
      " [ 1.50525451]\n",
      " [ 0.24552268]\n",
      " [-0.33748853]]\n",
      "27 Cost:  1.65556 \n",
      "Prediction:\n",
      " [[ 3.59685349]\n",
      " [ 2.20956993]\n",
      " [ 1.76511896]\n",
      " [ 1.2170831 ]\n",
      " [ 1.71041095]\n",
      " [ 1.50521314]\n",
      " [ 0.24549679]\n",
      " [-0.33751276]]\n",
      "28 Cost:  1.65546 \n",
      "Prediction:\n",
      " [[ 3.59679198]\n",
      " [ 2.20951414]\n",
      " [ 1.76507211]\n",
      " [ 1.2170471 ]\n",
      " [ 1.71036792]\n",
      " [ 1.50517166]\n",
      " [ 0.24547094]\n",
      " [-0.33753699]]\n",
      "29 Cost:  1.65536 \n",
      "Prediction:\n",
      " [[ 3.59673047]\n",
      " [ 2.20945811]\n",
      " [ 1.76502573]\n",
      " [ 1.21701109]\n",
      " [ 1.71032488]\n",
      " [ 1.50513029]\n",
      " [ 0.24544507]\n",
      " [-0.33756119]]\n",
      "30 Cost:  1.65526 \n",
      "Prediction:\n",
      " [[ 3.59666872]\n",
      " [ 2.20940208]\n",
      " [ 1.76497889]\n",
      " [ 1.21697497]\n",
      " [ 1.71028173]\n",
      " [ 1.50508904]\n",
      " [ 0.24541923]\n",
      " [-0.33758539]]\n",
      "31 Cost:  1.65516 \n",
      "Prediction:\n",
      " [[ 3.59660721]\n",
      " [ 2.20934629]\n",
      " [ 1.76493251]\n",
      " [ 1.21693897]\n",
      " [ 1.7102387 ]\n",
      " [ 1.50504768]\n",
      " [ 0.2453934 ]\n",
      " [-0.33760959]]\n",
      "32 Cost:  1.65506 \n",
      "Prediction:\n",
      " [[ 3.59654546]\n",
      " [ 2.20929003]\n",
      " [ 1.76488566]\n",
      " [ 1.21690297]\n",
      " [ 1.71019554]\n",
      " [ 1.50500631]\n",
      " [ 0.24536753]\n",
      " [-0.33763379]]\n",
      "33 Cost:  1.65495 \n",
      "Prediction:\n",
      " [[ 3.59648418]\n",
      " [ 2.20923424]\n",
      " [ 1.76483905]\n",
      " [ 1.21686685]\n",
      " [ 1.71015251]\n",
      " [ 1.50496495]\n",
      " [ 0.24534169]\n",
      " [-0.33765802]]\n",
      "34 Cost:  1.65485 \n",
      "Prediction:\n",
      " [[ 3.5964222 ]\n",
      " [ 2.20917797]\n",
      " [ 1.76479244]\n",
      " [ 1.21683097]\n",
      " [ 1.71010947]\n",
      " [ 1.50492346]\n",
      " [ 0.24531582]\n",
      " [-0.33768222]]\n",
      "35 Cost:  1.65475 \n",
      "Prediction:\n",
      " [[ 3.59636092]\n",
      " [ 2.20912218]\n",
      " [ 1.76474583]\n",
      " [ 1.21679485]\n",
      " [ 1.71006644]\n",
      " [ 1.5048821 ]\n",
      " [ 0.24528998]\n",
      " [-0.33770642]]\n",
      "36 Cost:  1.65465 \n",
      "Prediction:\n",
      " [[ 3.59629941]\n",
      " [ 2.20906615]\n",
      " [ 1.76469922]\n",
      " [ 1.21675885]\n",
      " [ 1.71002328]\n",
      " [ 1.50484085]\n",
      " [ 0.24526408]\n",
      " [-0.33773065]]\n",
      "37 Cost:  1.65455 \n",
      "Prediction:\n",
      " [[ 3.5962379 ]\n",
      " [ 2.20901012]\n",
      " [ 1.76465261]\n",
      " [ 1.21672285]\n",
      " [ 1.70998013]\n",
      " [ 1.50479937]\n",
      " [ 0.24523827]\n",
      " [-0.33775485]]\n",
      "38 Cost:  1.65445 \n",
      "Prediction:\n",
      " [[ 3.59617615]\n",
      " [ 2.20895386]\n",
      " [ 1.764606  ]\n",
      " [ 1.21668673]\n",
      " [ 1.7099371 ]\n",
      " [ 1.50475788]\n",
      " [ 0.24521241]\n",
      " [-0.33777905]]\n",
      "39 Cost:  1.65434 \n",
      "Prediction:\n",
      " [[ 3.59611464]\n",
      " [ 2.20889807]\n",
      " [ 1.76455939]\n",
      " [ 1.21665072]\n",
      " [ 1.70989394]\n",
      " [ 1.50471663]\n",
      " [ 0.24518654]\n",
      " [-0.33780324]]\n",
      "40 Cost:  1.65424 \n",
      "Prediction:\n",
      " [[ 3.59605289]\n",
      " [ 2.20884204]\n",
      " [ 1.76451278]\n",
      " [ 1.21661472]\n",
      " [ 1.70985103]\n",
      " [ 1.50467527]\n",
      " [ 0.2451607 ]\n",
      " [-0.33782747]]\n",
      "41 Cost:  1.65414 \n",
      "Prediction:\n",
      " [[ 3.59599161]\n",
      " [ 2.20878625]\n",
      " [ 1.76446593]\n",
      " [ 1.21657872]\n",
      " [ 1.70980775]\n",
      " [ 1.50463378]\n",
      " [ 0.24513486]\n",
      " [-0.33785167]]\n",
      "42 Cost:  1.65404 \n",
      "Prediction:\n",
      " [[ 3.59592962]\n",
      " [ 2.20872998]\n",
      " [ 1.76441956]\n",
      " [ 1.21654272]\n",
      " [ 1.70976472]\n",
      " [ 1.50459242]\n",
      " [ 0.24510902]\n",
      " [-0.33787587]]\n",
      "43 Cost:  1.65394 \n",
      "Prediction:\n",
      " [[ 3.59586835]\n",
      " [ 2.20867443]\n",
      " [ 1.76437294]\n",
      " [ 1.2165066 ]\n",
      " [ 1.70972168]\n",
      " [ 1.50455105]\n",
      " [ 0.24508312]\n",
      " [-0.3379001 ]]\n",
      "44 Cost:  1.65384 \n",
      "Prediction:\n",
      " [[ 3.59580684]\n",
      " [ 2.20861793]\n",
      " [ 1.76432633]\n",
      " [ 1.21647072]\n",
      " [ 1.70967853]\n",
      " [ 1.50450969]\n",
      " [ 0.24505731]\n",
      " [-0.3379243 ]]\n",
      "45 Cost:  1.65373 \n",
      "Prediction:\n",
      " [[ 3.59574533]\n",
      " [ 2.20856214]\n",
      " [ 1.76427948]\n",
      " [ 1.2164346 ]\n",
      " [ 1.70963562]\n",
      " [ 1.50446832]\n",
      " [ 0.24503145]\n",
      " [-0.3379485 ]]\n",
      "46 Cost:  1.65363 \n",
      "Prediction:\n",
      " [[ 3.59568357]\n",
      " [ 2.20850611]\n",
      " [ 1.76423311]\n",
      " [ 1.21639848]\n",
      " [ 1.70959258]\n",
      " [ 1.50442696]\n",
      " [ 0.24500561]\n",
      " [-0.3379727 ]]\n",
      "47 Cost:  1.65353 \n",
      "Prediction:\n",
      " [[ 3.59562206]\n",
      " [ 2.20845032]\n",
      " [ 1.76418626]\n",
      " [ 1.2163626 ]\n",
      " [ 1.70954931]\n",
      " [ 1.50438559]\n",
      " [ 0.24497975]\n",
      " [-0.3379969 ]]\n",
      "48 Cost:  1.65343 \n",
      "Prediction:\n",
      " [[ 3.59556031]\n",
      " [ 2.20839429]\n",
      " [ 1.76413989]\n",
      " [ 1.21632671]\n",
      " [ 1.70950627]\n",
      " [ 1.50434422]\n",
      " [ 0.24495393]\n",
      " [-0.3380211 ]]\n",
      "49 Cost:  1.65333 \n",
      "Prediction:\n",
      " [[ 3.59549904]\n",
      " [ 2.20833826]\n",
      " [ 1.76409316]\n",
      " [ 1.21629059]\n",
      " [ 1.70946324]\n",
      " [ 1.50430298]\n",
      " [ 0.24492811]\n",
      " [-0.3380453 ]]\n",
      "50 Cost:  1.65323 \n",
      "Prediction:\n",
      " [[ 3.59543705]\n",
      " [ 2.20828199]\n",
      " [ 1.76404655]\n",
      " [ 1.21625459]\n",
      " [ 1.7094202 ]\n",
      " [ 1.50426161]\n",
      " [ 0.24490222]\n",
      " [-0.3380695 ]]\n",
      "51 Cost:  1.65312 \n",
      "Prediction:\n",
      " [[ 3.59537578]\n",
      " [ 2.2082262 ]\n",
      " [ 1.76399994]\n",
      " [ 1.21621859]\n",
      " [ 1.70937705]\n",
      " [ 1.50422025]\n",
      " [ 0.24487643]\n",
      " [-0.33809367]]\n",
      "52 Cost:  1.65302 \n",
      "Prediction:\n",
      " [[ 3.5953145 ]\n",
      " [ 2.20817041]\n",
      " [ 1.76395333]\n",
      " [ 1.21618259]\n",
      " [ 1.7093339 ]\n",
      " [ 1.50417876]\n",
      " [ 0.24485058]\n",
      " [-0.33811784]]\n",
      "53 Cost:  1.65292 \n",
      "Prediction:\n",
      " [[ 3.59525275]\n",
      " [ 2.20811415]\n",
      " [ 1.76390672]\n",
      " [ 1.21614647]\n",
      " [ 1.70929098]\n",
      " [ 1.50413752]\n",
      " [ 0.24482475]\n",
      " [-0.33814204]]\n",
      "54 Cost:  1.65282 \n",
      "Prediction:\n",
      " [[ 3.59519124]\n",
      " [ 2.20805836]\n",
      " [ 1.76385987]\n",
      " [ 1.21611047]\n",
      " [ 1.70924795]\n",
      " [ 1.50409615]\n",
      " [ 0.2447989 ]\n",
      " [-0.33816624]]\n",
      "55 Cost:  1.65272 \n",
      "Prediction:\n",
      " [[ 3.59512949]\n",
      " [ 2.20800209]\n",
      " [ 1.7638135 ]\n",
      " [ 1.21607447]\n",
      " [ 1.70920467]\n",
      " [ 1.50405478]\n",
      " [ 0.24477307]\n",
      " [-0.33819044]]\n",
      "56 Cost:  1.65262 \n",
      "Prediction:\n",
      " [[ 3.59506798]\n",
      " [ 2.2079463 ]\n",
      " [ 1.763767  ]\n",
      " [ 1.21603847]\n",
      " [ 1.70916176]\n",
      " [ 1.50401354]\n",
      " [ 0.24474725]\n",
      " [-0.33821464]]\n",
      "57 Cost:  1.65251 \n",
      "Prediction:\n",
      " [[ 3.59500647]\n",
      " [ 2.20789027]\n",
      " [ 1.76372015]\n",
      " [ 1.21600258]\n",
      " [ 1.70911872]\n",
      " [ 1.50397205]\n",
      " [ 0.24472137]\n",
      " [-0.33823884]]\n",
      "58 Cost:  1.65241 \n",
      "Prediction:\n",
      " [[ 3.59494472]\n",
      " [ 2.20783401]\n",
      " [ 1.76367354]\n",
      " [ 1.21596658]\n",
      " [ 1.70907557]\n",
      " [ 1.50393081]\n",
      " [ 0.24469554]\n",
      " [-0.33826303]]\n",
      "59 Cost:  1.65231 \n",
      "Prediction:\n",
      " [[ 3.5948832 ]\n",
      " [ 2.20777822]\n",
      " [ 1.76362717]\n",
      " [ 1.21593046]\n",
      " [ 1.70903265]\n",
      " [ 1.50388944]\n",
      " [ 0.24466972]\n",
      " [-0.3382872 ]]\n",
      "60 Cost:  1.65221 \n",
      "Prediction:\n",
      " [[ 3.59482193]\n",
      " [ 2.20772243]\n",
      " [ 1.76358032]\n",
      " [ 1.21589446]\n",
      " [ 1.70898938]\n",
      " [ 1.50384796]\n",
      " [ 0.2446439 ]\n",
      " [-0.3383114 ]]\n",
      "61 Cost:  1.65211 \n",
      "Prediction:\n",
      " [[ 3.59476042]\n",
      " [ 2.2076664 ]\n",
      " [ 1.76353395]\n",
      " [ 1.21585846]\n",
      " [ 1.70894635]\n",
      " [ 1.50380671]\n",
      " [ 0.24461801]\n",
      " [-0.33833557]]\n",
      "62 Cost:  1.65201 \n",
      "Prediction:\n",
      " [[ 3.59469867]\n",
      " [ 2.20761037]\n",
      " [ 1.7634871 ]\n",
      " [ 1.21582246]\n",
      " [ 1.70890331]\n",
      " [ 1.50376523]\n",
      " [ 0.24459222]\n",
      " [-0.33835977]]\n",
      "63 Cost:  1.6519 \n",
      "Prediction:\n",
      " [[ 3.59463716]\n",
      " [ 2.20755458]\n",
      " [ 1.76344049]\n",
      " [ 1.21578634]\n",
      " [ 1.70886016]\n",
      " [ 1.50372374]\n",
      " [ 0.24456637]\n",
      " [-0.33838397]]\n",
      "64 Cost:  1.6518 \n",
      "Prediction:\n",
      " [[ 3.59457541]\n",
      " [ 2.20749831]\n",
      " [ 1.76339388]\n",
      " [ 1.21575046]\n",
      " [ 1.70881701]\n",
      " [ 1.50368261]\n",
      " [ 0.24454051]\n",
      " [-0.33840817]]\n",
      "65 Cost:  1.6517 \n",
      "Prediction:\n",
      " [[ 3.59451413]\n",
      " [ 2.20744252]\n",
      " [ 1.76334739]\n",
      " [ 1.21571445]\n",
      " [ 1.70877409]\n",
      " [ 1.50364125]\n",
      " [ 0.2445147 ]\n",
      " [-0.33843234]]\n",
      "66 Cost:  1.6516 \n",
      "Prediction:\n",
      " [[ 3.59445238]\n",
      " [ 2.20738649]\n",
      " [ 1.76330078]\n",
      " [ 1.21567845]\n",
      " [ 1.70873094]\n",
      " [ 1.50359976]\n",
      " [ 0.24448889]\n",
      " [-0.33845651]]\n",
      "67 Cost:  1.6515 \n",
      "Prediction:\n",
      " [[ 3.59439087]\n",
      " [ 2.20733047]\n",
      " [ 1.76325417]\n",
      " [ 1.21564245]\n",
      " [ 1.70868802]\n",
      " [ 1.5035584 ]\n",
      " [ 0.24446309]\n",
      " [-0.33848071]]\n",
      "68 Cost:  1.6514 \n",
      "Prediction:\n",
      " [[ 3.5943296 ]\n",
      " [ 2.20727468]\n",
      " [ 1.76320767]\n",
      " [ 1.21560645]\n",
      " [ 1.70864511]\n",
      " [ 1.50351715]\n",
      " [ 0.24443722]\n",
      " [-0.33850488]]\n",
      "69 Cost:  1.6513 \n",
      "Prediction:\n",
      " [[ 3.59426785]\n",
      " [ 2.20721841]\n",
      " [ 1.76316106]\n",
      " [ 1.21557045]\n",
      " [ 1.70860183]\n",
      " [ 1.5034759 ]\n",
      " [ 0.24441144]\n",
      " [-0.33852905]]\n",
      "70 Cost:  1.65119 \n",
      "Prediction:\n",
      " [[ 3.59420633]\n",
      " [ 2.20716262]\n",
      " [ 1.76311445]\n",
      " [ 1.21553445]\n",
      " [ 1.7085588 ]\n",
      " [ 1.50343442]\n",
      " [ 0.2443856 ]\n",
      " [-0.33855325]]\n",
      "71 Cost:  1.65109 \n",
      "Prediction:\n",
      " [[ 3.59414482]\n",
      " [ 2.20710659]\n",
      " [ 1.76306784]\n",
      " [ 1.21549845]\n",
      " [ 1.70851576]\n",
      " [ 1.50339305]\n",
      " [ 0.24435979]\n",
      " [-0.33857739]]\n",
      "72 Cost:  1.65099 \n",
      "Prediction:\n",
      " [[ 3.59408307]\n",
      " [ 2.20705056]\n",
      " [ 1.76302099]\n",
      " [ 1.21546245]\n",
      " [ 1.70847273]\n",
      " [ 1.50335169]\n",
      " [ 0.24433395]\n",
      " [-0.33860159]]\n",
      "73 Cost:  1.65089 \n",
      "Prediction:\n",
      " [[ 3.5940218 ]\n",
      " [ 2.20699453]\n",
      " [ 1.7629745 ]\n",
      " [ 1.21542656]\n",
      " [ 1.70842957]\n",
      " [ 1.50331044]\n",
      " [ 0.24430814]\n",
      " [-0.33862576]]\n",
      "74 Cost:  1.65079 \n",
      "Prediction:\n",
      " [[ 3.59395981]\n",
      " [ 2.20693874]\n",
      " [ 1.76292813]\n",
      " [ 1.21539056]\n",
      " [ 1.70838654]\n",
      " [ 1.50326908]\n",
      " [ 0.24428234]\n",
      " [-0.33864993]]\n",
      "75 Cost:  1.65069 \n",
      "Prediction:\n",
      " [[ 3.59389853]\n",
      " [ 2.20688248]\n",
      " [ 1.76288128]\n",
      " [ 1.21535444]\n",
      " [ 1.70834351]\n",
      " [ 1.50322771]\n",
      " [ 0.24425647]\n",
      " [-0.33867413]]\n",
      "76 Cost:  1.65059 \n",
      "Prediction:\n",
      " [[ 3.59383726]\n",
      " [ 2.20682693]\n",
      " [ 1.76283479]\n",
      " [ 1.21531844]\n",
      " [ 1.70830059]\n",
      " [ 1.50318623]\n",
      " [ 0.24423069]\n",
      " [-0.3386983 ]]\n",
      "77 Cost:  1.65048 \n",
      "Prediction:\n",
      " [[ 3.59377551]\n",
      " [ 2.20677066]\n",
      " [ 1.76278818]\n",
      " [ 1.21528256]\n",
      " [ 1.70825732]\n",
      " [ 1.5031451 ]\n",
      " [ 0.24420485]\n",
      " [-0.33872247]]\n",
      "78 Cost:  1.65038 \n",
      "Prediction:\n",
      " [[ 3.593714  ]\n",
      " [ 2.20671487]\n",
      " [ 1.76274157]\n",
      " [ 1.21524656]\n",
      " [ 1.70821428]\n",
      " [ 1.50310373]\n",
      " [ 0.24417904]\n",
      " [-0.33874667]]\n",
      "79 Cost:  1.65028 \n",
      "Prediction:\n",
      " [[ 3.59365249]\n",
      " [ 2.20665908]\n",
      " [ 1.76269495]\n",
      " [ 1.21521044]\n",
      " [ 1.70817125]\n",
      " [ 1.50306237]\n",
      " [ 0.2441532 ]\n",
      " [-0.33877084]]\n",
      "80 Cost:  1.65018 \n",
      "Prediction:\n",
      " [[ 3.59359074]\n",
      " [ 2.20660281]\n",
      " [ 1.76264834]\n",
      " [ 1.21517444]\n",
      " [ 1.70812821]\n",
      " [ 1.503021  ]\n",
      " [ 0.24412739]\n",
      " [-0.33879501]]\n",
      "81 Cost:  1.65008 \n",
      "Prediction:\n",
      " [[ 3.59352946]\n",
      " [ 2.20654702]\n",
      " [ 1.76260185]\n",
      " [ 1.21513855]\n",
      " [ 1.7080853 ]\n",
      " [ 1.50297964]\n",
      " [ 0.24410158]\n",
      " [-0.33881915]]\n",
      "82 Cost:  1.64998 \n",
      "Prediction:\n",
      " [[ 3.59346771]\n",
      " [ 2.20649099]\n",
      " [ 1.76255524]\n",
      " [ 1.21510255]\n",
      " [ 1.70804214]\n",
      " [ 1.50293839]\n",
      " [ 0.24407572]\n",
      " [-0.33884335]]\n",
      "83 Cost:  1.64988 \n",
      "Prediction:\n",
      " [[ 3.5934062 ]\n",
      " [ 2.20643497]\n",
      " [ 1.76250863]\n",
      " [ 1.21506643]\n",
      " [ 1.70799899]\n",
      " [ 1.50289702]\n",
      " [ 0.24404995]\n",
      " [-0.33886749]]\n",
      "84 Cost:  1.64977 \n",
      "Prediction:\n",
      " [[ 3.59334493]\n",
      " [ 2.20637918]\n",
      " [ 1.76246214]\n",
      " [ 1.21503067]\n",
      " [ 1.70795619]\n",
      " [ 1.50285578]\n",
      " [ 0.24402413]\n",
      " [-0.33889163]]\n",
      "85 Cost:  1.64967 \n",
      "Prediction:\n",
      " [[ 3.59328341]\n",
      " [ 2.20632339]\n",
      " [ 1.76241553]\n",
      " [ 1.21499455]\n",
      " [ 1.70791304]\n",
      " [ 1.50281441]\n",
      " [ 0.24399836]\n",
      " [-0.33891577]]\n",
      "86 Cost:  1.64957 \n",
      "Prediction:\n",
      " [[ 3.59322166]\n",
      " [ 2.20626736]\n",
      " [ 1.76236892]\n",
      " [ 1.21495867]\n",
      " [ 1.70787001]\n",
      " [ 1.50277305]\n",
      " [ 0.24397254]\n",
      " [-0.33893991]]\n",
      "87 Cost:  1.64947 \n",
      "Prediction:\n",
      " [[ 3.59316039]\n",
      " [ 2.20621157]\n",
      " [ 1.76232243]\n",
      " [ 1.21492267]\n",
      " [ 1.70782709]\n",
      " [ 1.5027318 ]\n",
      " [ 0.24394675]\n",
      " [-0.33896405]]\n",
      "88 Cost:  1.64937 \n",
      "Prediction:\n",
      " [[ 3.59309912]\n",
      " [ 2.20615578]\n",
      " [ 1.76227605]\n",
      " [ 1.21488667]\n",
      " [ 1.70778406]\n",
      " [ 1.50269043]\n",
      " [ 0.24392095]\n",
      " [-0.33898818]]\n",
      "89 Cost:  1.64927 \n",
      "Prediction:\n",
      " [[ 3.59303737]\n",
      " [ 2.20609975]\n",
      " [ 1.76222932]\n",
      " [ 1.21485078]\n",
      " [ 1.70774102]\n",
      " [ 1.50264931]\n",
      " [ 0.24389516]\n",
      " [-0.33901232]]\n",
      "90 Cost:  1.64917 \n",
      "Prediction:\n",
      " [[ 3.59297585]\n",
      " [ 2.20604396]\n",
      " [ 1.76218295]\n",
      " [ 1.21481478]\n",
      " [ 1.70769811]\n",
      " [ 1.50260794]\n",
      " [ 0.24386933]\n",
      " [-0.33903649]]\n",
      "91 Cost:  1.64907 \n",
      "Prediction:\n",
      " [[ 3.59291458]\n",
      " [ 2.20598817]\n",
      " [ 1.76213634]\n",
      " [ 1.21477878]\n",
      " [ 1.70765495]\n",
      " [ 1.5025667 ]\n",
      " [ 0.24384354]\n",
      " [-0.3390606 ]]\n",
      "92 Cost:  1.64896 \n",
      "Prediction:\n",
      " [[ 3.59285307]\n",
      " [ 2.20593214]\n",
      " [ 1.76208985]\n",
      " [ 1.2147429 ]\n",
      " [ 1.70761192]\n",
      " [ 1.50252533]\n",
      " [ 0.24381775]\n",
      " [-0.33908474]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Cost:  1.64886 \n",
      "Prediction:\n",
      " [[ 3.59279156]\n",
      " [ 2.20587611]\n",
      " [ 1.76204324]\n",
      " [ 1.2147069 ]\n",
      " [ 1.70756888]\n",
      " [ 1.50248408]\n",
      " [ 0.24379192]\n",
      " [-0.33910891]]\n",
      "94 Cost:  1.64876 \n",
      "Prediction:\n",
      " [[ 3.59273005]\n",
      " [ 2.20582056]\n",
      " [ 1.76199675]\n",
      " [ 1.21467113]\n",
      " [ 1.70752597]\n",
      " [ 1.50244284]\n",
      " [ 0.24376613]\n",
      " [-0.33913305]]\n",
      "95 Cost:  1.64866 \n",
      "Prediction:\n",
      " [[ 3.59266853]\n",
      " [ 2.20576429]\n",
      " [ 1.76195037]\n",
      " [ 1.21463501]\n",
      " [ 1.70748293]\n",
      " [ 1.50240147]\n",
      " [ 0.24374036]\n",
      " [-0.33915719]]\n",
      "96 Cost:  1.64856 \n",
      "Prediction:\n",
      " [[ 3.59260726]\n",
      " [ 2.20570874]\n",
      " [ 1.76190352]\n",
      " [ 1.21459901]\n",
      " [ 1.7074399 ]\n",
      " [ 1.50236011]\n",
      " [ 0.24371454]\n",
      " [-0.33918133]]\n",
      "97 Cost:  1.64846 \n",
      "Prediction:\n",
      " [[ 3.59254575]\n",
      " [ 2.20565271]\n",
      " [ 1.76185703]\n",
      " [ 1.21456313]\n",
      " [ 1.70739698]\n",
      " [ 1.50231886]\n",
      " [ 0.24368872]\n",
      " [-0.33920547]]\n",
      "98 Cost:  1.64836 \n",
      "Prediction:\n",
      " [[ 3.592484  ]\n",
      " [ 2.20559692]\n",
      " [ 1.76181042]\n",
      " [ 1.21452713]\n",
      " [ 1.70735395]\n",
      " [ 1.50227749]\n",
      " [ 0.24366295]\n",
      " [-0.33922961]]\n",
      "99 Cost:  1.64825 \n",
      "Prediction:\n",
      " [[ 3.59242272]\n",
      " [ 2.20554066]\n",
      " [ 1.76176405]\n",
      " [ 1.21449113]\n",
      " [ 1.70731091]\n",
      " [ 1.50223613]\n",
      " [ 0.24363713]\n",
      " [-0.33925375]]\n",
      "100 Cost:  1.64815 \n",
      "Prediction:\n",
      " [[ 3.59236145]\n",
      " [ 2.20548511]\n",
      " [ 1.76171756]\n",
      " [ 1.21445525]\n",
      " [ 1.707268  ]\n",
      " [ 1.50219488]\n",
      " [ 0.24361134]\n",
      " [-0.33927789]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
