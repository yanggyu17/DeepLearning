{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "#dropout rate\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"dropout_3/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#32개 필터 사용\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#print(L1) #shape=(?, 28, 28, 32)\n",
    "L1 = tf.nn.relu(L1)\n",
    "#print(L1) #shape=(?, 28, 28, 32)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#print(L1) #shape=(?, 14, 14, 32)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "#print(L1) #shape=(?, 14, 14, 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_7:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_7:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_7:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"dropout_7/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#print(L2) #shape=(?, 14, 14, 64)\n",
    "L2 = tf.nn.relu(L2)\n",
    "#print(L2) #shape=(?, 14, 14, 64)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#print(L2) #shape=(?, 7, 7, 64)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "#print(L2) #shape=(?, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC(Fully Connected) layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128*4*4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4 = tf.get_variable(\"W4\", shape=[128*4*4, 625],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost =  0.465079199\n",
      "Epoch:  0002 cost =  0.089887623\n",
      "Epoch:  0003 cost =  0.065933095\n",
      "Epoch:  0004 cost =  0.053503707\n",
      "Epoch:  0005 cost =  0.049286312\n",
      "Epoch:  0006 cost =  0.043236367\n",
      "Epoch:  0007 cost =  0.038988581\n",
      "Epoch:  0008 cost =  0.034783542\n",
      "Epoch:  0009 cost =  0.034928359\n",
      "Epoch:  0010 cost =  0.030698844\n",
      "Epoch:  0011 cost =  0.029538121\n",
      "Epoch:  0012 cost =  0.027125532\n",
      "Epoch:  0013 cost =  0.027583106\n",
      "Epoch:  0014 cost =  0.025174285\n",
      "Epoch:  0015 cost =  0.023193498\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    \n",
    "    print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9947\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy:  0.9947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1P8DiPsZpcM/K8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174c8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
